# INTRODUCTION
The field of data engineering is becoming more and more important in the dynamic world of data-driven decision-making. Data extraction, transformation, and loading (ETL) of data from many sources to relevant destinations is made easier by data pipelines, which constitute the foundation of workflows for data processing. With the help of the potent mix of Python and Apache NiFi, this project is designed for beginners and will walk you through the process of creating a simple yet informative data pipeline.

# Project synopsis:-

Assisting novices in data engineering with practical knowledge of building a fundamental ETL data pipeline is the main objective of this project. The user-friendly data integration tool Apache NiFi will coordinate the pipeline, which will include obtaining data from a source, modifying it with Python scripts, and loading the changed data into a destination.


Technology and Instruments:

Python: A general-purpose programming language that is widely used for data-related activities due to its ease of use and versatility.
Apache NFI: An open-source data integration tool called Apache NiFi has an intuitive user interface that makes it possible to create intricate data flows.
SQLLite: SQLite is a simple relational database that is lightweight and appropriate for small to medium-sized applications. It is the database used in this example for beginners.
